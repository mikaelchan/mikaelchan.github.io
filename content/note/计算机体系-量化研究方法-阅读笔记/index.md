+++
date = '2025-09-13T22:10:30+08:00'
title = '《计算机体系结构：量化研究方法》阅读笔记'
tags = ['CS', 'Optimization']
+++
最近又看了一遍《计算机体系结构：量化研究方法》（第六版），不得不感叹不愧是圣经，在此记录一下。这本书在摩尔定律（Moore's Law）放缓和登纳德缩放定律（Dennard Scaling）失效的背景下，为未来的计算范式指明了方向 。本书的核心思想在于“量化”二字，即通过严格的公式、度量标准和经验法则来指导设计决策，而非仅仅依赖直觉或过往经验。
<!--more-->
{{<katex>}}

## 1 并行计算的历史背景
第一章介绍了并行计算的历史背景和一些量化公式。

### 1.1 技术趋势与设计的转折点
在过去的几十年里，通用处理器的性能提升主要依赖于晶体管密度的增加和频率的提升。然而，第六版明确指出了一个时代的终结：登纳德缩放定律在2005年左右失效，导致功率密度不再随着晶体管缩小而恒定，频率提升遭遇“功耗墙”；随后，摩尔定律的经济效益也开始减弱 。这一系列物理层面的阻碍迫使体系结构设计发生了根本性的转变——从单纯追求指令级并行（ILP）转向挖掘线程级并行（TLP）和数据级并行（DLP），并最终走向了领域专用架构（Domain-Specific Architectures, DSAs）的新黄金时代 。

### 1.2 性能评测与量化公式

体系结构设计的基石是性能公式。CPU时间是衡量性能的最终标准，其经典公式为：$$\text{CPU Time} = \text{Instruction Count} \times \text{CPI} \times \text{Clock Cycle Time}$$
这一公式揭示了性能优化的三个维度：通过编译器或ISA设计减少指令数（Instruction Count）；通过微架构创新（如流水线、乱序执行）降低每指令周期数（CPI）；通过工艺制程改进或加深流水线级数来缩短时钟周期时间 。

在并行计算时代，阿姆达尔定律（Amdahl's Law）依然是不可逾越的铁律。它量化了系统加速比的理论上限：$$\text{Speedup}\_{\text{overall}} = \frac{1}{(1 - \text{Fraction}\_{\text{enhanced}}) + \frac{\text{Fraction}\_{\text{enhanced}}}{\text{Speedup}\_{\text{enhanced}}}}$$

该定律指出，无论并行处理单元有多少，系统的整体加速比最终受限于那些必须串行执行的部分。如果一个程序中有10%的部分无法并行化，那么即便拥有无限的处理器，最大加速比也无法超过10倍。这一洞见直接推动了针对特定瓶颈进行加速的异构计算（如GPU和TPU）的发展 。

### 1.3 功耗与能量的物理约束
随着工艺制程进入纳米级，功耗已取代面积成为首要的设计约束。功耗分为动态功耗和静态功耗：
+ **动态功耗（Dynamic Power）**： \(P_{dynamic} \propto \frac{1}{2} \times C \times V^2 \times f\)。由于电压（V）与功耗的平方关系，降低电压是节能的最有效手段。然而，随着电压逼近阈值电压，进一步降压变得极度困难，限制了频率（f）的提升。
+ **静态功耗（Static Power）**： \(P_{static} \propto V \times I_{leakage}\)。随着晶体管尺寸缩小，漏电流（$I_{leakage}$）显著增加，使得静态功耗在总功耗中的占比不断攀升 。

这种功耗约束导致了“暗硅”（Dark Silicon）现象，即芯片上必须有很大一部分区域在任何时刻都处于关闭状态以防止过热。这进一步强化了向专用加速器转型的逻辑：与其让通用核心空转，不如使用高能效比的专用硬件来完成特定任务。

### 1.4 可靠性与可用性
在仓库级计算机（WSC）的规模下，硬件故障是常态而非异常。因此，设计必须遵循“无单点故障”原则。系统的可用性（Availability）被定义为：$$\text{Availability} = \frac{\text{MTTF}}{\text{MTTF} + \text{MTTR}}$$
其中MTTF（平均无故障时间）衡量可靠性，MTTR（平均修复时间）衡量可维护性。通过冗余设计和快速故障转移机制来最小化MTTR，是构建大规模分布式系统的关键策略 。

## 2. 存储层次结构设计

存储器性能的提升速度远落后于处理器，导致了著名的“存储墙”（Memory Wall）问题。第二章深入探讨了通过多级缓存（Cache）层次结构来弥合这一差距的技术细节。
### 2.1 缓存性能的量化分析
缓存设计的核心目标是降低平均内存访问时间（AMAT）：$$\text{AMAT} = \text{Hit Time} + \text{Miss Rate} \times \text{Miss Penalty}$$
为了优化AMAT，设计者必须在减少命中时间、降低缺失率和减少缺失代价之间进行权衡。本书提出了经典的“2:1缓存法则”：一个大小为N的直接映射缓存的缺失率，大致等于大小为N/2的两路组相联缓存的缺失率 。这为在容量和关联度之间做快速估算提供了依据。
### 2.2 十大高级缓存优化技术
为了进一步压榨存储性能，第六版详细阐述了十种高级缓存优化技术。这些技术分别针对AMAT公式中的不同变量 ：
|优化技术|目标|技术原理与机制|权衡与代价|
|--|--|--|--|
|1. 小而简单的L1缓存|减少命中时间|将L1缓存设计得足够小（如32KB-64KB）且关联度较低，以确保其访问能在一个时钟周期内完成，通常采用虚索引实标记（VIPT）。|增加了缺失率；需要L2缓存来弥补。|
|2. 路预测 (Way Prediction)|减少命中时间|在缓存访问前预测数据所在的“路”（Way），只激活该路的数据RAM，从而减少功耗并加快访问速度。|预测错误会增加延迟（通常多一个周期）和能耗。|
|3. 流水线化缓存访问|增加带宽|将缓存访问过程分解为多个流水线级（如索引、标签比较、数据读出），允许高频时钟。|增加了加载指令的延迟（Load-to-use latency），虽然吞吐量增加了。|
|4. 非阻塞缓存 (Non-blocking)|增加带宽|允许“缺失下命中”（Hit-under-Miss），即在处理一个缺失请求时，缓存仍能服务后续的请求。依赖于MSHR（缺失状态保持寄存器）。|控制逻辑极度复杂，是乱序执行处理器的标配。|
|5. 多体缓存 (Multibanked)|增加带宽|将缓存划分为多个独立的体（Bank），支持并发访问。通常利用地址的低位进行交叉存取。|需要复杂的交叉开关（Crossbar）网络来连接CPU和各Bank。|
|6. 关键字优先与提前重启|减少缺失代价|关键字优先：先从内存请求CPU急需的那个字，收到后立即发给CPU。提前重启：一旦收到请求字，不等整个块填充完毕即恢复执行。|内存控制器的逻辑更加复杂。|
|7. 合并写缓冲区|减少缺失代价|检查写缓冲区中的现有条目，如果新的写操作针对同一地址或同一块，则合并写入，减少对下级存储的写入次数。|需要多路比较器来检查地址匹配。|
|8. 编译器优化|减少缺失率|循环分块（Blocking）：提高时间局部性；循环交换：改善空间局部性；数据以此重排。|完全依赖软件，无硬件成本，但在复杂代码中难以实现。|
|9. 硬件预取 (Prefetching)|减少缺失率/代价|硬件监控内存访问模式（如指令流或数据流步长），预测并提前加载数据。|可能造成缓存污染（加载无用数据）和带宽浪费。|
|10. 编译器控制预取|减少缺失率/代价|编译器插入专门的预取指令，在数据使用前将其加载到缓存或专用缓冲区。|增加了指令数（Instruction Count），可能抢占执行单元资源。|

### 2.3 虚拟机与保护机制
虚拟内存不仅提供了地址空间的抽象，更是系统安全和多任务隔离的基石。在现代体系结构中，TLB（转译后备缓冲器）是虚拟内存性能的关键。为了应对大内存应用（如数据库和机器学习），现代处理器支持多种页面大小（如4KB、2MB、1GB）。大页面可以显著减少TLB缺失，因为每个TLB条目覆盖的内存范围更广 。

在虚拟化环境中，为了支持虚拟机（VM），体系结构引入了嵌套页表（Nested Page Tables）或扩展页表（EPT），硬件直接支持从客户机物理地址到宿主机物理地址的转换，极大地降低了虚拟化的开销。

## 3. 指令级并行（ILP）
第三章的核心在于如何挖掘指令流中的并行性。随着静态流水线达到瓶颈，硬件动态调度成为提升性能的关键。

### 3.1 Tomasulo算法
Tomasulo算法最初在IBM 360/91浮点单元中实现，它通过硬件机制实现了乱序执行，以此掩盖长延迟操作。其核心创新在于引入了 **保留站（Reservation Stations, RS）** 和 **公共数据总线（Common Data Bus, CDB）** 。
Tomasulo算法主要解决三类数据相关：
1. 写后读（RAW）：这是真数据相关。Tomasulo通过在保留站中等待源操作数就绪来解决。如果操作数未在寄存器中，保留站会监听CDB，一旦结果产生，直接捕获，无需经过寄存器堆。
2. 读后写（WAR）和写后写（WAW）：这是名相关。Tomasulo通过寄存器重命名技术消除这些伪相关。当指令发射时，目的寄存器被映射到保留站的ID，后续指令依赖的是该保留站ID而非架构寄存器，从而允许指令乱序完成 。

### 3.2 基于硬件的推测执行（Speculation）与重排序缓冲区（ROB）
纯粹的Tomasulo算法虽然支持乱序执行，但无法支持**精确异常（Precise Exceptions）**和**分支预测推测**。为了解决这个问题，现代处理器引入了**重排序缓冲区（Reorder Buffer, ROB）** 。

引入ROB后的流水线变为四个阶段：
1. **发射（Issue）**： 指令从指令队列取出，分配保留站（RS）和ROB条目。如果操作数在寄存器或ROB中就绪，则送入RS；否则，记录产生该操作数的ROB编号。
2. **执行（Execute）**： 如果操作数都已就绪且功能单元空闲，则开始执行。此阶段处理RAW冲突。
3. **写结果（Write Result）**： 计算结果通过CDB广播。结果不仅写入等待的RS，也写入对应的ROB条目。注意：此时不写入架构寄存器堆。
4. **提交（Commit）**： 这是新增的关键阶段。指令必须按照程序顺序从ROB头部移除。只有当指令是ROB中最旧的且已完成时，其结果才真正写入架构寄存器或内存。如果该指令是分支指令且预测错误，或者发生异常，处理器可以清空ROB，回滚状态，从而保证精确异常和正确的推测执行 。

**ROB与保留站的区别：** 保留站负责解决执行所需的依赖（重命名源操作数），而ROB负责维护程序顺序和未提交的架构状态（重命名目的操作数）。

## 4. 数据级并行（DLP）
第四章标志着视角的转换，从挖掘单一指令流的并行性转向挖掘数据的并行性。这是理解现代AI加速器和高性能计算的基础。
### 4.1 向量架构（Vector Architecture）
向量处理器（如Cray-1）通过一条指令对一组数据进行操作。其核心组件包括向量寄存器（通常很大，如64个元素）、流水线化的功能单元和高带宽的内存系统。

向量架构的一个关键特性是**收集-分散（Gather-Scatter）**支持。这允许处理器使用索引向量来加载或存储非连续内存地址的数据（例如 load V1, base + V_index），这对于处理稀疏矩阵至关重要 。此外，**掩码寄存器（Mask Registers）**允许对向量中的特定元素进行条件执行，解决了向量化循环中的if-else控制流问题。

### 4.2 GPU架构深度剖析：从图形到通用计算
GPU（图形处理单元）代表了另一种DLP的实现路径。Hennessy和Patterson将GPU的执行模型定义为**单指令多线程（SIMT）**。与传统SIMD不同，SIMT允许程序员以“线程”的视角编写代码，而硬件负责将这些线程聚合成组（Warp）进行锁步执行。

### 4.2.1 CUDA编程模型与硬件映射
为了深入理解GPU，必须建立CUDA软件概念与NVIDIA硬件架构之间的精确映射关系 ：
|CUDA 软件概念|NVIDIA 硬件实体|描述与功能|
|-|-|-|
|线程 (Thread)|CUDA Core / Lane|最小的执行单元，拥有私有的寄存器状态和局部内存。|
|线程块 (Thread Block)|多处理器 (SM)|线程块被分配给一个SM执行。SM管理块内的共享内存、寄存器分配和Warp调度。一个块一旦分配给SM，就会驻留直到执行完毕。|
|网格 (Grid)|GPU (Device)|包含所有线程块的集合，可能分布在整个GPU的多个SM上执行。|
|Warp (线束)|Warp|硬件调度的基本单位。通常包含32个线程。Warp内的线程执行同一条指令（SIMD行为）。|

### 4.2.2 流多处理器（SM）的微架构细节
SM是GPU的核心。一个SM通常包含：
+ CUDA Cores：分为INT32单元、FP32单元和FP64单元。
+ 寄存器堆（Register File）：GPU拥有巨大的片上寄存器资源（例如Volta架构中每SM 256KB），这是为了支持成千上万个活跃线程的上下文切换（Zero-overhead context switching）。
+ Warp调度器（Warp Scheduler）：SM中有多个Warp调度器。每个周期，调度器从就绪队列中选择一个Warp发射指令。这种机制通过多线程掩盖了内存延迟——当一个Warp等待内存时，立即切换到另一个Warp执行计算 。

### 4.2.3 关键性能瓶颈与优化机制
1. Warp分歧（Warp Divergence）： 在SIMT模型中，Warp内的32个线程共享一个程序计数器（PC）。如果代码中出现if-else分支，且Warp内部分线程走if，部分走else，硬件会串行化执行：先执行if路径（禁用else线程），再执行else路径（禁用if线程）。这会显著降低吞吐量。优化策略是避免同一Warp内的线程出现控制流分歧 。
2. 存储器合并（Memory Coalescing）： 全局内存（Global Memory）的访问延迟极高。硬件内存控制器被设计为当Warp内的线程访问连续对齐的内存地址时，将这些请求合并为极少量的DRAM事务。如果访问是跨步的（Strided）或随机的，会导致大量未合并的事务，极大地浪费带宽 。
3. 共享内存与Bank冲突（Bank Conflicts）： 共享内存（Shared Memory）是片上的低延迟SRAM，被划分为32个Bank。如果一个Warp内的多个线程同时访问同一个Bank的不同地址，访问必须串行化，这就是Bank冲突。解决方法通常是引入填充（Padding），例如声明数组__shared__ float data而不是``，从而错开列访问的Bank映射 。

## 5. 线程级并行（TLP）
随着单核性能停滞，多核处理器成为主流。第五章深入探讨了多核系统中的核心难题：如何让多个处理器不仅能并行工作，还能正确地共享数据。

### 5.1 缓存一致性协议：监听与目录
当多个核心的缓存中存有同一内存块的副本时，如果一个核心修改了数据，如何通知其他核心？这就是缓存一致性问题。
+ 监听协议（Snooping Protocols）： 适用于核心数较少（如<16）的总线互连系统。
    - 机制： 所有缓存控制器都监听（Snoop）总线上的事务。当核A要写入数据时，它在总线上广播“写失效”（Write Invalidate）信号，其他核监听到该地址后，使其副本失效。
    - 状态机： 典型的MESI协议包括Modified（已修改，独占且脏）、Exclusive（独占且干净）、Shared（共享）、Invalid（无效）四种状态。局限： 广播机制极其消耗带宽，无法扩展到大量核心 。
+ 目录协议（Directory Protocols）： 适用于大规模多核系统（众核）。
    - 机制： 系统的共享状态维护在一个集中的（或分布式的）“目录”中。目录记录了哪个核心持有哪个块的副本。
    - 流程： 当核A想写入时，它向目录发送请求。目录查找该块的共享者列表（如核B和C），仅向B和C发送失效消息。B和C确认失效后，目录授权A写入。
    - 优势： 避免了全网广播，通信是点对点的，具有更好的扩展性。
    - 代价： 增加了访问延迟（请求者 -> 目录 -> 共享者 -> 目录 -> 请求者）和目录存储开销 。
    
### 5.2 内存一致性模型（Memory Consistency Models
一致性（Coherence）关注的是“写操作最终能被看到”，而一致性模型（Consistency）关注的是“写操作何时被看到”以及“不同地址操作的顺序”。
+ 顺序一致性（Sequential Consistency, SC）： 最直观的模型。所有处理器的操作看起来都像是按程序顺序执行的，且所有处理器看到的操作交织顺序是一致的。这禁止了写缓冲（Write Buffer）和预读等硬件优化，性能较差 。
+ 完全存储定序（Total Store Ordering, TSO）： x86架构采用此模型。允许“写-读”乱序（即读操作可以越过之前的写操作），因为引入了写缓冲区（Store Buffer）。但所有写操作之间必须保持顺序。程序员在写同步代码时通常不需要显式栅栏（Fence），除了极少数情况。
+ 松弛一致性（Relaxed Consistency）： 如ARM和RISC-V（Weak Memory Ordering）。允许读写操作的大幅度乱序（读读、写写、读写都可以乱序），以最大化硬件效率。程序员必须显式使用**内存屏障（Memory Barrier/Fence）**指令来强制排序，以确保同步操作的正确性 。

## 6. 仓库级计算机（WSC）：作为一台计算机的数据中心
第六章将视角从微观芯片拉大到宏观的数据中心。在这一尺度上，WSC不仅仅是一堆服务器的集合，它本身就是一台巨大的计算机，其设计目标是极致的成本效益（Cost-Performance）和能源效率。
### 6.1 关键度量标准：PUE与TCO
+ PUE（能源使用效率）： 衡量WSC基础设施效率的核心指标。$$\text{PUE} = \frac{\text{Total Facility Power}}{\text{IT Equipment Power}}$$
PUE越接近1.0越好，意味着用于冷却和配电的额外能耗越少。Google等公司通过先进的冷却技术（如自然冷却、高温运行）将PUE降至1.1左右 。
+ TCO（总拥有成本）： 包括资本支出（CAPEX，如服务器购置、建筑成本）和运营支出（OPEX，如电费、维护）。Watt-Year法则指出，每瓦特功耗的年均综合成本约为2美元（2011年数据），这凸显了能效的重要性 。
### 6.2 WSC的架构特征
WSC采用商用现货（COTS）组件，利用软件冗余来解决硬件不可靠问题（依赖性规则）。其网络通常采用Clos拓扑结构，提供高对半带宽（Bisection Bandwidth），以支持大规模分布式计算框架（如MapReduce）产生的海量东西向流量。

## 7. 领域专用架构（DSA）s
第七章是第六版新增的精华，标志着通用计算向专用计算的范式转移。面对深度神经网络（DNN）对算力的贪婪需求，通用CPU和GPU已显疲态。
### 7.1 DSA设计的七大指导原则
Hennessy和Patterson总结了设计高效DSA的七大原则 ：
1. 使用专用存储器： 摒弃通用的缓存层次结构，使用软件管理的暂存器（Scratchpad Memory），以最大化带宽并提供确定的延迟。
2. 利用领域特定的并行性： 针对特定算法（如矩阵乘法）设计并行模式，而非追求通用的MIMD。
3. 减少数据移动： 数据移动的能耗远高于计算。将计算单元放置在数据附近。
4. 降低数据精度： DNN推断通常不需要FP32或FP64。使用INT8或BF16可以大幅减少带宽需求和ALU面积。
5. 投资于算力而非控制： 去掉分支预测、乱序执行逻辑，将晶体管用于更多的ALU和存储器。
6. 使用领域专用语言（DSL）： 将高级操作直接映射到硬件原语，跨越传统的ISA鸿沟。
7. 利用ASIC的能效优势： 定制芯片可以针对特定工作负载进行极致的物理设计优化。